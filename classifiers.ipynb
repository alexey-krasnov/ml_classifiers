{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b5a876-b7a8-4150-bee9-6c737d7289a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\"\"\"Prediction of survival at the Titanic with GradientBoosting classifier\"\"\"\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split, cross_val_score, RepeatedKFold, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,  HistGradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b33a3184-77a1-463b-a20a-f56d66ce6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_time(start:float, end:float) -> float:\n",
    "    \"\"\"Measures code runtime, returns value in milliseconds rounded to 4 decimal places.\"\"\"\n",
    "    diff_time = (end - start) * 1000\n",
    "    return round(diff_time, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dff69a9-2000-4b64-adbd-435dc1fb8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_pred) -> map:\n",
    "    \"\"\"Calculates the main model metrics - accuracy, balanced-Accuracy, recall, precision`, f1_score and returns them as a map object\"\"\"\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    balanced_accuracy = metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    f_1 = metrics.f1_score(y_test, y_pred)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    metrics = map(lambda element: round(element, 4), (accuracy, balanced_accuracy, precision, recall, f_1, roc_auc))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd2a7f8a-0148-4f4c-ad61-5724241fc264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 20) (5000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.79818937e+00,  4.53015277e+00,  4.22403615e-03, ...,\n",
       "          1.02597489e+00,  4.27126411e+00,  6.61644026e-01],\n",
       "        [ 6.93138828e-01, -1.76468266e+00,  2.30285684e-01, ...,\n",
       "         -1.59501947e+00,  1.76354883e+00, -4.27768545e-01],\n",
       "        [ 6.58166152e-01, -3.19425213e+00,  8.05843890e-02, ...,\n",
       "         -6.28951404e-01, -2.99132020e+00, -9.92600787e-02],\n",
       "        ...,\n",
       "        [-8.78901958e-01,  2.19683613e+00, -1.71063685e+00, ...,\n",
       "          1.65315937e-01,  1.89641658e+00, -5.91270778e-01],\n",
       "        [ 1.89973102e+00, -1.31447362e+00, -5.56524415e-01, ...,\n",
       "         -1.63908172e+00, -1.10436920e+00,  1.47530500e+00],\n",
       "        [-5.20090832e-01, -2.64398607e+00, -1.22005814e+00, ...,\n",
       "         -1.82798431e-01, -2.30324798e+00,  4.37861623e-01]]),\n",
       " array([1, 1, 1, ..., 0, 1, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define test classification dataset\n",
    "X, y = make_classification(n_samples=5000, n_features=20, n_informative=5, n_redundant=2, random_state=12)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)\n",
    "# Split for train/test data as 80% and 20 %\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b7eb8c9-7795-4733-b068-fc349e12e251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(),\n",
       " GradientBoostingClassifier(),\n",
       " HistGradientBoostingClassifier(),\n",
       " XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, gamma=None,\n",
       "               gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "               num_parallel_tree=None, predictor=None, random_state=None,\n",
       "               reg_alpha=None, reg_lambda=None, ...),\n",
       " LGBMClassifier(),\n",
       " <catboost.core.CatBoostClassifier at 0x17b2a4670>,\n",
       " MLPClassifier(max_iter=1000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instance the classification models\n",
    "rf = RandomForestClassifier()\n",
    "gb = GradientBoostingClassifier()\n",
    "hist_gb = HistGradientBoostingClassifier()\n",
    "xgb = XGBClassifier()\n",
    "lgb = LGBMClassifier()\n",
    "catgb = CatBoostClassifier(verbose=0, n_estimators=200)\n",
    "mlp = MLPClassifier(max_iter=1000)\n",
    "\n",
    "models = (rf, gb, hist_gb, xgb, lgb, catgb, mlp)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f99d79b-e97b-47b9-8b2a-f7619d37bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cross_validation(estimator, X_train, y_train, cv=5):\n",
    "    scorings = ('accuracy', 'balanced_accuracy', 'f1', 'precision', 'recall',  'roc_auc')\n",
    "    scores = cross_validate(estimator, X_train, y_train, cv=cv, n_jobs=-1, scoring=scorings)\n",
    "    scores.items()\n",
    "    final_metrics = dict()\n",
    "    for key, item in sorted(scores.items()):\n",
    "        # print(f'{key} is {item.mean().round(4)}')\n",
    "        final_metrics[key] = item.mean().round(4)\n",
    "    return final_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4c2587e-11e6-4c35-9017-72039ff52aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier()</th>\n",
       "      <td>1.4515</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.9268</td>\n",
       "      <td>0.9268</td>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.9263</td>\n",
       "      <td>0.9753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier()</th>\n",
       "      <td>2.9569</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.9282</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>0.9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier()</th>\n",
       "      <td>0.6874</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>0.9339</td>\n",
       "      <td>0.9339</td>\n",
       "      <td>0.9344</td>\n",
       "      <td>0.9361</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.9810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier(base_score=None, booster=None, callbacks=None,\\n              colsample_bylevel=None, colsample_bynode=None,\\n              colsample_bytree=None, early_stopping_rounds=None,\\n              enable_categorical=False, eval_metric=None, gamma=None,\\n              gpu_id=None, grow_policy=None, importance_type=None,\\n              interaction_constraints=None, learning_rate=None, max_bin=None,\\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\\n              max_leaves=None, min_child_weight=None, missing=nan,\\n              monotone_constraints=None, n_estimators=100, n_jobs=None,\\n              num_parallel_tree=None, predictor=None, random_state=None,\\n              reg_alpha=None, reg_lambda=None, ...)</th>\n",
       "      <td>2.3399</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.9335</td>\n",
       "      <td>0.9338</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9309</td>\n",
       "      <td>0.9795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier()</th>\n",
       "      <td>0.3436</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.9344</td>\n",
       "      <td>0.9344</td>\n",
       "      <td>0.9349</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>0.9335</td>\n",
       "      <td>0.9809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;catboost.core.CatBoostClassifier object at 0x17b2a4670&gt;</th>\n",
       "      <td>2.4475</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.9389</td>\n",
       "      <td>0.9389</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.9429</td>\n",
       "      <td>0.9357</td>\n",
       "      <td>0.9820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier(max_iter=1000)</th>\n",
       "      <td>9.0588</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>0.9261</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.9754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    fit_time  score_time  \\\n",
       "RandomForestClassifier()                              1.4515      0.0542   \n",
       "GradientBoostingClassifier()                          2.9569      0.0105   \n",
       "HistGradientBoostingClassifier()                      0.6874      0.0327   \n",
       "XGBClassifier(base_score=None, booster=None, ca...    2.3399      0.0187   \n",
       "LGBMClassifier()                                      0.3436      0.0400   \n",
       "<catboost.core.CatBoostClassifier object at 0x1...    2.4475      0.0318   \n",
       "MLPClassifier(max_iter=1000)                          9.0588      0.0070   \n",
       "\n",
       "                                                    test_accuracy  \\\n",
       "RandomForestClassifier()                                   0.9268   \n",
       "GradientBoostingClassifier()                               0.9279   \n",
       "HistGradientBoostingClassifier()                           0.9339   \n",
       "XGBClassifier(base_score=None, booster=None, ca...         0.9334   \n",
       "LGBMClassifier()                                           0.9344   \n",
       "<catboost.core.CatBoostClassifier object at 0x1...         0.9389   \n",
       "MLPClassifier(max_iter=1000)                               0.9240   \n",
       "\n",
       "                                                    test_balanced_accuracy  \\\n",
       "RandomForestClassifier()                                            0.9268   \n",
       "GradientBoostingClassifier()                                        0.9279   \n",
       "HistGradientBoostingClassifier()                                    0.9339   \n",
       "XGBClassifier(base_score=None, booster=None, ca...                  0.9335   \n",
       "LGBMClassifier()                                                    0.9344   \n",
       "<catboost.core.CatBoostClassifier object at 0x1...                  0.9389   \n",
       "MLPClassifier(max_iter=1000)                                        0.9240   \n",
       "\n",
       "                                                    test_f1  test_precision  \\\n",
       "RandomForestClassifier()                             0.9273          0.9286   \n",
       "GradientBoostingClassifier()                         0.9282          0.9322   \n",
       "HistGradientBoostingClassifier()                     0.9344          0.9361   \n",
       "XGBClassifier(base_score=None, booster=None, ca...   0.9338          0.9369   \n",
       "LGBMClassifier()                                     0.9349          0.9364   \n",
       "<catboost.core.CatBoostClassifier object at 0x1...   0.9392          0.9429   \n",
       "MLPClassifier(max_iter=1000)                         0.9245          0.9261   \n",
       "\n",
       "                                                    test_recall  test_roc_auc  \n",
       "RandomForestClassifier()                                 0.9263        0.9753  \n",
       "GradientBoostingClassifier()                             0.9245        0.9762  \n",
       "HistGradientBoostingClassifier()                         0.9328        0.9810  \n",
       "XGBClassifier(base_score=None, booster=None, ca...       0.9309        0.9795  \n",
       "LGBMClassifier()                                         0.9335        0.9809  \n",
       "<catboost.core.CatBoostClassifier object at 0x1...       0.9357        0.9820  \n",
       "MLPClassifier(max_iter=1000)                             0.9231        0.9754  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=12)\n",
    "data = []\n",
    "for mdl in models:\n",
    "    report_dict = make_cross_validation(mdl, X_train, y_train, cv=cv)\n",
    "    data.append(report_dict)\n",
    "df_report = pd.DataFrame(data, index=models)\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc371acc-f3d0-4a61-b10b-d4fafebcff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fitting(estimator, X_train, y_train):\n",
    "    estimator.fit(X_train, y_train)\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6f07e64-f2d4-41df-849e-d717366713c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(estimator, X_test):\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e31f28-5fbe-44d1-8bd3-f6a33277192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing the best model: RandomForestClassifier()\n",
      "Accuracy: 0.946, Balanced Accuracy: 0.946, Precision 0.9419,  Recall 0.9458, F1_score 0.9439\n",
      "\n",
      "Testing the best model: GradientBoostingClassifier()\n",
      "Accuracy: 0.937, Balanced Accuracy: 0.937, Precision 0.9317,  Recall 0.9375, F1_score 0.9346\n",
      "\n",
      "Testing the best model: HistGradientBoostingClassifier()\n",
      "Accuracy: 0.945, Balanced Accuracy: 0.9446, Precision 0.9493,  Recall 0.9354, F1_score 0.9423\n",
      "\n",
      "Testing the best model: XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n",
      "Accuracy: 0.945, Balanced Accuracy: 0.9449, Precision 0.9436,  Recall 0.9417, F1_score 0.9426\n",
      "\n",
      "Testing the best model: LGBMClassifier()\n",
      "Accuracy: 0.942, Balanced Accuracy: 0.9414, Precision 0.9509,  Recall 0.9271, F1_score 0.9388\n",
      "\n",
      "Testing the best model: <catboost.core.CatBoostClassifier object at 0x17b2a4670>\n",
      "Accuracy: 0.949, Balanced Accuracy: 0.9486, Precision 0.9535,  Recall 0.9396, F1_score 0.9465\n",
      "\n",
      "Testing the best model: MLPClassifier(max_iter=1000)\n",
      "Accuracy: 0.931, Balanced Accuracy: 0.9314, Precision 0.9168,  Recall 0.9417, F1_score 0.9291\n"
     ]
    }
   ],
   "source": [
    "for mdl in models:\n",
    "    mdl.fit(X_train, y_train)\n",
    "    # estimator = make_fitting(mdl, X_train, y_train)\n",
    "    # y_pred = make_prediction(estimator, X_test)\n",
    "    y_pred = mdl.predict(X_test)\n",
    "    accaracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    bal_accuracy = metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    f1_score = metrics.f1_score(y_test, y_pred)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    # mult_nb_balanced_accuracy, mult_nb_precision, mult_nb_recall, mult_nb_f1_score = get_metrics(y_test, y_pred)\n",
    "    print(f'\\nTesting the best model: {mdl}')\n",
    "    print(f\"Accuracy: {accaracy.round(4)}, Balanced Accuracy: {bal_accuracy.round(4)}, Precision {precision.round(4)},  Recall {recall.round(4)}, F1_score {f1_score.round(4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
