{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c2ee52f-f3e1-46af-a431-b759433a89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\"\"\"Evaluation performance of the most popular classification algorithms\"\"\"\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b33a3184-77a1-463b-a20a-f56d66ce6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_time(start:float, end:float) -> float:\n",
    "    \"\"\"Measures code runtime, returns value in milliseconds rounded to 4 decimal places.\"\"\"\n",
    "    diff_time = (end - start) * 1000\n",
    "    return round(diff_time, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd2a7f8a-0148-4f4c-ad61-5724241fc264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 7) (2000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.98494061, -0.72572549,  0.22255677, ...,  1.8681878 ,\n",
       "         -2.79671927,  1.97024335],\n",
       "        [ 1.38692078,  1.73777061, -1.43049967, ...,  0.43809266,\n",
       "          0.0605342 , -0.12174517],\n",
       "        [ 0.76319675,  1.37060634, -1.46835557, ..., -0.11028388,\n",
       "          0.1486933 ,  0.14285945],\n",
       "        ...,\n",
       "        [-1.2845685 , -0.80567947,  1.29232843, ...,  0.47524624,\n",
       "         -0.36037226,  1.01687246],\n",
       "        [ 1.34254657, -0.17345118, -1.61236257, ..., -0.41292282,\n",
       "         -1.28293218,  0.42119896],\n",
       "        [ 0.31942181, -1.80482244,  0.02086189, ..., -0.00609257,\n",
       "         -1.48429554, -0.35664264]]),\n",
       " array([1, 1, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define test classification dataset\n",
    "X, y = make_classification(n_samples=2000, n_features=7, n_informative=5, n_redundant=2, random_state=12)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)\n",
    "# Split for train/test data as 80% and 20 %\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7eb8c9-7795-4733-b068-fc349e12e251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(),\n",
       " GradientBoostingClassifier(),\n",
       " HistGradientBoostingClassifier(),\n",
       " XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, gamma=None,\n",
       "               gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "               num_parallel_tree=None, predictor=None, random_state=None,\n",
       "               reg_alpha=None, reg_lambda=None, ...),\n",
       " LGBMClassifier(),\n",
       " <catboost.core.CatBoostClassifier at 0x26dd34a5a20>,\n",
       " MLPClassifier(max_iter=1000, solver='lbfgs'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instance the classification models\n",
    "rf = RandomForestClassifier()\n",
    "gb = GradientBoostingClassifier()\n",
    "hist_gb = HistGradientBoostingClassifier()\n",
    "xgb = XGBClassifier()\n",
    "lgb = LGBMClassifier()\n",
    "catgb = CatBoostClassifier(verbose=0, n_estimators=200)\n",
    "mlp = MLPClassifier(max_iter=1000, solver='lbfgs')\n",
    "models = (rf, gb, hist_gb, xgb, lgb, catgb, mlp)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f99d79b-e97b-47b9-8b2a-f7619d37bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cross_validation(estimator, X_train, y_train, cv=5):\n",
    "    \"\"\"Perform cross validation and teturn metrics:\n",
    "    accuracy, balanced_accuracy, f1, precision, recall, roc_auc\"\"\"\n",
    "    scorings = ('accuracy', 'balanced_accuracy', 'f1', 'precision', 'recall', 'roc_auc')\n",
    "    scores = cross_validate(estimator, X_train, y_train, cv=cv, n_jobs=-1, scoring=scorings)\n",
    "    final_metrics = dict()\n",
    "    for key, item in sorted(scores.items()):\n",
    "        final_metrics[key] = item.mean().round(4)\n",
    "    return final_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4c2587e-11e6-4c35-9017-72039ff52aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier()</th>\n",
       "      <td>0.2502</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.9248</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.9253</td>\n",
       "      <td>0.9747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier()</th>\n",
       "      <td>0.2728</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.9144</td>\n",
       "      <td>0.9144</td>\n",
       "      <td>0.9138</td>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.9710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier()</th>\n",
       "      <td>0.3713</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.9282</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>0.9280</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier(base_score=None, booster=None, callbacks=None,\\n              colsample_bylevel=None, colsample_bynode=None,\\n              colsample_bytree=None, early_stopping_rounds=None,\\n              enable_categorical=False, eval_metric=None, gamma=None,\\n              gpu_id=None, grow_policy=None, importance_type=None,\\n              interaction_constraints=None, learning_rate=None, max_bin=None,\\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\\n              max_leaves=None, min_child_weight=None, missing=nan,\\n              monotone_constraints=None, n_estimators=100, n_jobs=None,\\n              num_parallel_tree=None, predictor=None, random_state=None,\\n              reg_alpha=None, reg_lambda=None, ...)</th>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.9265</td>\n",
       "      <td>0.9265</td>\n",
       "      <td>0.9264</td>\n",
       "      <td>0.9265</td>\n",
       "      <td>0.9269</td>\n",
       "      <td>0.9785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier()</th>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.9285</td>\n",
       "      <td>0.9285</td>\n",
       "      <td>0.9285</td>\n",
       "      <td>0.9280</td>\n",
       "      <td>0.9296</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;catboost.core.CatBoostClassifier object at 0x0000026DD34A5A20&gt;</th>\n",
       "      <td>1.0294</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9332</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>0.9339</td>\n",
       "      <td>0.9817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier(max_iter=1000, solver='lbfgs')</th>\n",
       "      <td>0.4852</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.9264</td>\n",
       "      <td>0.9264</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.9271</td>\n",
       "      <td>0.9258</td>\n",
       "      <td>0.9730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    fit_time  score_time  \\\n",
       "RandomForestClassifier()                              0.2502      0.0358   \n",
       "GradientBoostingClassifier()                          0.2728      0.0060   \n",
       "HistGradientBoostingClassifier()                      0.3713      0.0149   \n",
       "XGBClassifier(base_score=None, booster=None, ca...    0.1992      0.0088   \n",
       "LGBMClassifier()                                      0.1017      0.0110   \n",
       "<catboost.core.CatBoostClassifier object at 0x0...    1.0294      0.0083   \n",
       "MLPClassifier(max_iter=1000, solver='lbfgs')          0.4852      0.0062   \n",
       "\n",
       "                                                    test_accuracy  \\\n",
       "RandomForestClassifier()                                   0.9249   \n",
       "GradientBoostingClassifier()                               0.9144   \n",
       "HistGradientBoostingClassifier()                           0.9282   \n",
       "XGBClassifier(base_score=None, booster=None, ca...         0.9265   \n",
       "LGBMClassifier()                                           0.9285   \n",
       "<catboost.core.CatBoostClassifier object at 0x0...         0.9331   \n",
       "MLPClassifier(max_iter=1000, solver='lbfgs')               0.9264   \n",
       "\n",
       "                                                    test_balanced_accuracy  \\\n",
       "RandomForestClassifier()                                            0.9249   \n",
       "GradientBoostingClassifier()                                        0.9144   \n",
       "HistGradientBoostingClassifier()                                    0.9283   \n",
       "XGBClassifier(base_score=None, booster=None, ca...                  0.9265   \n",
       "LGBMClassifier()                                                    0.9285   \n",
       "<catboost.core.CatBoostClassifier object at 0x0...                  0.9332   \n",
       "MLPClassifier(max_iter=1000, solver='lbfgs')                        0.9264   \n",
       "\n",
       "                                                    test_f1  test_precision  \\\n",
       "RandomForestClassifier()                             0.9248          0.9249   \n",
       "GradientBoostingClassifier()                         0.9138          0.9182   \n",
       "HistGradientBoostingClassifier()                     0.9280          0.9290   \n",
       "XGBClassifier(base_score=None, booster=None, ca...   0.9264          0.9265   \n",
       "LGBMClassifier()                                     0.9285          0.9280   \n",
       "<catboost.core.CatBoostClassifier object at 0x0...   0.9331          0.9330   \n",
       "MLPClassifier(max_iter=1000, solver='lbfgs')         0.9262          0.9271   \n",
       "\n",
       "                                                    test_recall  test_roc_auc  \n",
       "RandomForestClassifier()                                 0.9253        0.9747  \n",
       "GradientBoostingClassifier()                             0.9101        0.9710  \n",
       "HistGradientBoostingClassifier()                         0.9279        0.9792  \n",
       "XGBClassifier(base_score=None, booster=None, ca...       0.9269        0.9785  \n",
       "LGBMClassifier()                                         0.9296        0.9792  \n",
       "<catboost.core.CatBoostClassifier object at 0x0...       0.9339        0.9817  \n",
       "MLPClassifier(max_iter=1000, solver='lbfgs')             0.9258        0.9730  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=12)\n",
    "data_cross_val = []\n",
    "for mdl in models:\n",
    "    report_dict = make_cross_validation(mdl, X_train, y_train, cv=cv)\n",
    "    data_cross_val.append(report_dict)\n",
    "df_report = pd.DataFrame(data_cross_val, index=[str(mdl) for mdl in models])\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dff69a9-2000-4b64-adbd-435dc1fb8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluation(estimator, X_train, y_train, X_test, y_test) -> dict:\n",
    "    \"\"\"Calculates the main model metrics - accuracy, balanced-Accuracy, \n",
    "    recall, precision, f1_score on the test set and returns them as a map object.\"\"\"\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred).round(4)\n",
    "    balanced_accuracy = metrics.balanced_accuracy_score(y_test, y_pred).round(4)\n",
    "    precision = metrics.precision_score(y_test, y_pred).round(4)\n",
    "    f_1 = metrics.f1_score(y_test, y_pred).round(4)\n",
    "    recall = metrics.recall_score(y_test, y_pred).round(4)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_pred).round(4)\n",
    "\n",
    "    final_metrics = {'accuracy': accuracy,\n",
    "                     'balanced_accuracy': balanced_accuracy,\n",
    "                     'f1': f_1,\n",
    "                     'precision': precision,\n",
    "                     'recall': recall,\n",
    "                     'roc_auc': roc_auc,\n",
    "                    }\n",
    "    # Use dict comprehension for round dict values \n",
    "    final_metrics = {key:round(val, 4) for key, val in final_metrics.items()} \n",
    "    return final_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72e31f28-5fbe-44d1-8bd3-f6a33277192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the models on the test set: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier()</th>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9453</td>\n",
       "      <td>0.9475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier()</th>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.9451</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>0.9303</td>\n",
       "      <td>0.9451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier()</th>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>0.9552</td>\n",
       "      <td>0.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\\n              early_stopping_rounds=None, enable_categorical=False,\\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\\n              importance_type=None, interaction_constraints='',\\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\\n              missing=nan, monotone_constraints='()', n_estimators=100,\\n              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\\n              reg_alpha=0, reg_lambda=1, ...)</th>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>0.9475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier()</th>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.9461</td>\n",
       "      <td>0.9602</td>\n",
       "      <td>0.9525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;catboost.core.CatBoostClassifier object at 0x0000026DD34A5A20&gt;</th>\n",
       "      <td>0.9575</td>\n",
       "      <td>0.9575</td>\n",
       "      <td>0.9578</td>\n",
       "      <td>0.9554</td>\n",
       "      <td>0.9602</td>\n",
       "      <td>0.9575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier(max_iter=1000, solver='lbfgs')</th>\n",
       "      <td>0.9575</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>0.9694</td>\n",
       "      <td>0.9453</td>\n",
       "      <td>0.9576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy  \\\n",
       "RandomForestClassifier()                              0.9475   \n",
       "GradientBoostingClassifier()                          0.9450   \n",
       "HistGradientBoostingClassifier()                      0.9600   \n",
       "XGBClassifier(base_score=0.5, booster='gbtree',...    0.9475   \n",
       "LGBMClassifier()                                      0.9525   \n",
       "<catboost.core.CatBoostClassifier object at 0x0...    0.9575   \n",
       "MLPClassifier(max_iter=1000, solver='lbfgs')          0.9575   \n",
       "\n",
       "                                                    balanced_accuracy      f1  \\\n",
       "RandomForestClassifier()                                       0.9475  0.9476   \n",
       "GradientBoostingClassifier()                                   0.9451  0.9444   \n",
       "HistGradientBoostingClassifier()                               0.9600  0.9600   \n",
       "XGBClassifier(base_score=0.5, booster='gbtree',...             0.9475  0.9474   \n",
       "LGBMClassifier()                                               0.9525  0.9531   \n",
       "<catboost.core.CatBoostClassifier object at 0x0...             0.9575  0.9578   \n",
       "MLPClassifier(max_iter=1000, solver='lbfgs')                   0.9576  0.9572   \n",
       "\n",
       "                                                    precision  recall  roc_auc  \n",
       "RandomForestClassifier()                               0.9500  0.9453   0.9475  \n",
       "GradientBoostingClassifier()                           0.9590  0.9303   0.9451  \n",
       "HistGradientBoostingClassifier()                       0.9648  0.9552   0.9600  \n",
       "XGBClassifier(base_score=0.5, booster='gbtree',...     0.9545  0.9403   0.9475  \n",
       "LGBMClassifier()                                       0.9461  0.9602   0.9525  \n",
       "<catboost.core.CatBoostClassifier object at 0x0...     0.9554  0.9602   0.9575  \n",
       "MLPClassifier(max_iter=1000, solver='lbfgs')           0.9694  0.9453   0.9576  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the models on the test set\n",
    "data_test = []\n",
    "for mdl in models:\n",
    "    report_dict_test = test_evaluation(mdl, X_train, y_train, X_test, y_test)\n",
    "    data_test.append(report_dict_test)\n",
    "print('Evaluate the models on the test set: ')\n",
    "df_report_test = pd.DataFrame(data_test, index=[str(mdl) for mdl in models])\n",
    "df_report_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
