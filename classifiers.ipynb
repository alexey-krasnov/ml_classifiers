{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c2ee52f-f3e1-46af-a431-b759433a89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\"\"\"Evaluation performance of the most popular classification algorithms with\n",
    "    artificial dataset generated by sklearn.datasets.make_classification()\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd2a7f8a-0148-4f4c-ad61-5724241fc264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the dataset: X.shape is (1000, 10); y.shape is (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Define test classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=2, random_state=12)\n",
    "print(f\"Summarize the dataset: X.shape is {X.shape}; y.shape is {y.shape}\")\n",
    "# Split for train/test data as 80% and 20 %\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b7eb8c9-7795-4733-b068-fc349e12e251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(),\n",
       " RandomForestClassifier(),\n",
       " GradientBoostingClassifier(),\n",
       " HistGradientBoostingClassifier(),\n",
       " XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, gamma=None,\n",
       "               gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "               num_parallel_tree=None, predictor=None, random_state=None,\n",
       "               reg_alpha=None, reg_lambda=None, ...),\n",
       " LGBMClassifier(),\n",
       " <catboost.core.CatBoostClassifier at 0x290922ecb50>,\n",
       " MLPClassifier(max_iter=1500))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instances of the classification models\n",
    "lr = LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "gb = GradientBoostingClassifier()\n",
    "hist_gb = HistGradientBoostingClassifier()\n",
    "xgb = XGBClassifier()\n",
    "lgb = LGBMClassifier()\n",
    "catgb = CatBoostClassifier(verbose=0, n_estimators=200)\n",
    "mlp = MLPClassifier(max_iter=1500, solver='adam')\n",
    "\n",
    "models = (lr, rf, gb, hist_gb, xgb, lgb, catgb, mlp)\n",
    "models_tuple = ('LogisticRegression',\n",
    "                'RandomForestClassifier',\n",
    "                'GradientBoostingClassifier',\n",
    "                'HistGradientBoostingClassifier',\n",
    "                'XGBClassifier',\n",
    "                'LGBMClassifier',\n",
    "                'CatBoostClassifier',\n",
    "                'MLPClassifier',\n",
    "                )\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f99d79b-e97b-47b9-8b2a-f7619d37bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cross_validation(estimator, X_train, y_train, cv=5):\n",
    "    \"\"\"Perform cross validation and teturn metrics:\n",
    "    accuracy, balanced_accuracy, f1, precision, recall, roc_auc\"\"\"\n",
    "    scorings = ('accuracy', 'balanced_accuracy', 'f1', 'precision', 'recall', 'roc_auc')\n",
    "    scores = cross_validate(estimator, X_train, y_train, cv=cv, n_jobs=-1, scoring=scorings)\n",
    "    final_metrics = dict()\n",
    "    for key, item in sorted(scores.items()):\n",
    "        final_metrics[key] = item.mean().round(4)\n",
    "    return final_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4c2587e-11e6-4c35-9017-72039ff52aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.8325</td>\n",
       "      <td>0.8323</td>\n",
       "      <td>0.8362</td>\n",
       "      <td>0.8291</td>\n",
       "      <td>0.8449</td>\n",
       "      <td>0.9049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.2058</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.9671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.2442</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.8994</td>\n",
       "      <td>0.9016</td>\n",
       "      <td>0.8958</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.9584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier</th>\n",
       "      <td>0.3038</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.9278</td>\n",
       "      <td>0.9278</td>\n",
       "      <td>0.9285</td>\n",
       "      <td>0.9309</td>\n",
       "      <td>0.9269</td>\n",
       "      <td>0.9721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>0.9224</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.9289</td>\n",
       "      <td>0.9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.9238</td>\n",
       "      <td>0.9238</td>\n",
       "      <td>0.9247</td>\n",
       "      <td>0.9264</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>1.6041</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>0.9301</td>\n",
       "      <td>0.9317</td>\n",
       "      <td>0.9247</td>\n",
       "      <td>0.9393</td>\n",
       "      <td>0.9745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>3.3061</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.9342</td>\n",
       "      <td>0.9342</td>\n",
       "      <td>0.9354</td>\n",
       "      <td>0.9317</td>\n",
       "      <td>0.9398</td>\n",
       "      <td>0.9762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fit_time  score_time  test_accuracy  \\\n",
       "LogisticRegression                0.0040      0.0054         0.8325   \n",
       "RandomForestClassifier            0.2058      0.0311         0.9018   \n",
       "GradientBoostingClassifier        0.2442      0.0062         0.8995   \n",
       "HistGradientBoostingClassifier    0.3038      0.0110         0.9278   \n",
       "XGBClassifier                     0.1211      0.0084         0.9225   \n",
       "LGBMClassifier                    0.1442      0.0132         0.9238   \n",
       "CatBoostClassifier                1.6041      0.0090         0.9302   \n",
       "MLPClassifier                     3.3061      0.0056         0.9342   \n",
       "\n",
       "                                test_balanced_accuracy  test_f1  \\\n",
       "LogisticRegression                              0.8323   0.8362   \n",
       "RandomForestClassifier                          0.9017   0.9035   \n",
       "GradientBoostingClassifier                      0.8994   0.9016   \n",
       "HistGradientBoostingClassifier                  0.9278   0.9285   \n",
       "XGBClassifier                                   0.9224   0.9240   \n",
       "LGBMClassifier                                  0.9238   0.9247   \n",
       "CatBoostClassifier                              0.9301   0.9317   \n",
       "MLPClassifier                                   0.9342   0.9354   \n",
       "\n",
       "                                test_precision  test_recall  test_roc_auc  \n",
       "LogisticRegression                      0.8291       0.8449        0.9049  \n",
       "RandomForestClassifier                  0.8995       0.9081        0.9671  \n",
       "GradientBoostingClassifier              0.8958       0.9081        0.9584  \n",
       "HistGradientBoostingClassifier          0.9309       0.9269        0.9721  \n",
       "XGBClassifier                           0.9198       0.9289        0.9711  \n",
       "LGBMClassifier                          0.9264       0.9235        0.9711  \n",
       "CatBoostClassifier                      0.9247       0.9393        0.9745  \n",
       "MLPClassifier                           0.9317       0.9398        0.9762  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=12)\n",
    "data_cross_val = []\n",
    "for mdl in models:\n",
    "    report_dict = make_cross_validation(mdl, X_train, y_train, cv=cv)\n",
    "    data_cross_val.append(report_dict)\n",
    "df_report = pd.DataFrame(data_cross_val, index=models_tuple)\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0dff69a9-2000-4b64-adbd-435dc1fb8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluation(estimator, X_train, y_train, X_test, y_test) -> dict:\n",
    "    \"\"\"Calculates the main model metrics - accuracy, balanced-Accuracy,\n",
    "    recall, precision, f1_score on the test set and returns them as a map object.\"\"\"\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred).round(4)\n",
    "    balanced_accuracy = metrics.balanced_accuracy_score(y_test, y_pred).round(4)\n",
    "    precision = metrics.precision_score(y_test, y_pred).round(4)\n",
    "    f_1 = metrics.f1_score(y_test, y_pred).round(4)\n",
    "    recall = metrics.recall_score(y_test, y_pred).round(4)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_pred).round(4)\n",
    "\n",
    "    final_metrics = {'accuracy': accuracy,\n",
    "                     'balanced_accuracy': balanced_accuracy,\n",
    "                     'f1': f_1,\n",
    "                     'precision': precision,\n",
    "                     'recall': recall,\n",
    "                     'roc_auc': roc_auc,\n",
    "                    }\n",
    "    # Use dict comprehension for round dict values\n",
    "    final_metrics = {key: round(val, 4) for key, val in final_metrics.items()}\n",
    "    return final_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72e31f28-5fbe-44d1-8bd3-f6a33277192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the models on the test set: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.8438</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.8438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>0.9255</td>\n",
       "      <td>0.8878</td>\n",
       "      <td>0.9096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.8847</td>\n",
       "      <td>0.8808</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>0.8847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier</th>\n",
       "      <td>0.940</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.9196</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9362</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.9196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.930</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.9498</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>0.9498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.945</td>\n",
       "      <td>0.9447</td>\n",
       "      <td>0.9430</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.9447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                accuracy  balanced_accuracy      f1  \\\n",
       "LogisticRegression                 0.845             0.8438  0.8324   \n",
       "RandomForestClassifier             0.910             0.9096  0.9062   \n",
       "GradientBoostingClassifier         0.885             0.8847  0.8808   \n",
       "HistGradientBoostingClassifier     0.940             0.9400  0.9388   \n",
       "XGBClassifier                      0.920             0.9196  0.9167   \n",
       "LGBMClassifier                     0.930             0.9300  0.9286   \n",
       "CatBoostClassifier                 0.950             0.9498  0.9485   \n",
       "MLPClassifier                      0.945             0.9447  0.9430   \n",
       "\n",
       "                                precision  recall  roc_auc  \n",
       "LogisticRegression                 0.8851  0.7857   0.8438  \n",
       "RandomForestClassifier             0.9255  0.8878   0.9096  \n",
       "GradientBoostingClassifier         0.8947  0.8673   0.8847  \n",
       "HistGradientBoostingClassifier     0.9388  0.9388   0.9400  \n",
       "XGBClassifier                      0.9362  0.8980   0.9196  \n",
       "LGBMClassifier                     0.9286  0.9286   0.9300  \n",
       "CatBoostClassifier                 0.9583  0.9388   0.9498  \n",
       "MLPClassifier                      0.9579  0.9286   0.9447  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the models on the test set\n",
    "data_test = []\n",
    "for mdl in models:\n",
    "    report_dict_test = test_evaluation(mdl, X_train, y_train, X_test, y_test)\n",
    "    data_test.append(report_dict_test)\n",
    "print('Evaluate the models on the test set: ')\n",
    "df_report_test = pd.DataFrame(data_test, index=models_tuple)\n",
    "df_report_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
